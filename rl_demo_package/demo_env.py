"""
æ¼”ç¤ºç¯å¢ƒå¦‚ä½•ç”Ÿæˆæ•°æ®çš„è„šæœ¬
å±•ç¤ºç¯å¢ƒçš„çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±ç­‰æ•°æ®ç”Ÿæˆè¿‡ç¨‹
"""
import numpy as np
from env import DecisionEnv

def demo_environment():
    """æ¼”ç¤ºç¯å¢ƒçš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹"""
    print("=" * 60)
    print("å¼ºåŒ–å­¦ä¹ ç¯å¢ƒæ•°æ®ç”Ÿæˆæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç¯å¢ƒ
    env = DecisionEnv()
    
    # æ¼”ç¤º1: ç¯å¢ƒé‡ç½® - ç”Ÿæˆåˆå§‹çŠ¶æ€
    print("\nã€æ¼”ç¤º1ã€‘ç¯å¢ƒé‡ç½® - ç”Ÿæˆåˆå§‹éšæœºçŠ¶æ€")
    print("-" * 60)
    obs, info = env.reset(seed=42)  # ä½¿ç”¨å›ºå®šç§å­ä»¥ä¾¿å¤ç°
    print(f"åˆå§‹è§‚å¯Ÿ (observation): {obs}")
    print(f"è§‚å¯Ÿç©ºé—´å½¢çŠ¶: {obs.shape}")
    print(f"è§‚å¯Ÿç©ºé—´èŒƒå›´: [-100, 100]")
    print(f"å½“å‰è‡ªè½¦é€Ÿåº¦: {env.ego_speed:.2f}")
    print(f"å½“å‰éšœç¢ç‰©è·ç¦»: {env.obs_dist:.2f}")
    
    # æ¼”ç¤º2: æ‰§è¡Œå¤šä¸ªåŠ¨ä½œ - å±•ç¤ºçŠ¶æ€è½¬æ¢
    print("\nã€æ¼”ç¤º2ã€‘æ‰§è¡ŒåŠ¨ä½œ - çŠ¶æ€åŠ¨æ€å˜åŒ–")
    print("-" * 60)
    print(f"{'æ­¥éª¤':<6} {'åŠ¨ä½œ':<8} {'é€Ÿåº¦':<8} {'è·ç¦»':<10} {'å¥–åŠ±':<8} {'ç»ˆæ­¢':<6}")
    print("-" * 60)
    
    actions = [0, 0, 1, 2, 0, 1, 3]  # é¢„å®šä¹‰çš„åŠ¨ä½œåºåˆ—
    action_names = {0: "go", 1: "yield", 2: "slow", 3: "stop"}
    
    for step, action in enumerate(actions, 1):
        action_name = action_names[action]
        obs_before = obs.copy()
        speed_before = env.ego_speed
        dist_before = env.obs_dist
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, reward, terminated, truncated, info = env.step(action)
        
        print(f"{step:<6} {action_name:<8} {env.ego_speed:>6.2f}  {env.obs_dist:>8.2f}  {reward:>6.2f}  {terminated!s:<6}")
        
        if terminated:
            print(f"\nâš ï¸  ç¯å¢ƒç»ˆæ­¢ï¼åŸå› : ", end="")
            if env.obs_dist < 2:
                print("ç¢°æ’ï¼ˆè·ç¦» < 2ï¼‰")
            elif env.obs_dist > 30:
                print("æˆåŠŸé€šè¿‡ï¼ˆè·ç¦» > 30ï¼‰")
            break
    
    # æ¼”ç¤º3: å¤šæ¬¡é‡ç½® - å±•ç¤ºéšæœºæ€§
    print("\nã€æ¼”ç¤º3ã€‘å¤šæ¬¡é‡ç½® - å±•ç¤ºåˆå§‹çŠ¶æ€çš„éšæœºæ€§")
    print("-" * 60)
    print(f"{'é‡ç½®æ¬¡æ•°':<10} {'åˆå§‹é€Ÿåº¦':<12} {'åˆå§‹è·ç¦»':<12}")
    print("-" * 60)
    
    for i in range(5):
        obs, _ = env.reset()
        print(f"{i+1:<10} {env.ego_speed:>10.2f}  {env.obs_dist:>10.2f}")
    
    # æ¼”ç¤º4: å®Œæ•´episode - å±•ç¤ºå®Œæ•´çš„æ•°æ®æµ
    print("\nã€æ¼”ç¤º4ã€‘å®Œæ•´Episode - å±•ç¤ºå®Œæ•´çš„æ•°æ®ç”Ÿæˆæµç¨‹")
    print("-" * 60)
    
    obs, _ = env.reset(seed=123)
    total_reward = 0
    step_count = 0
    
    print(f"åˆå§‹çŠ¶æ€: é€Ÿåº¦={env.ego_speed:.2f}, è·ç¦»={env.obs_dist:.2f}")
    print("\næ‰§è¡ŒéšæœºåŠ¨ä½œåºåˆ—:")
    
    while step_count < 50:  # æœ€å¤š50æ­¥
        # éšæœºé€‰æ‹©åŠ¨ä½œï¼ˆå®é™…è®­ç»ƒä¸­ç”±ç­–ç•¥ç½‘ç»œå†³å®šï¼‰
        action = env.action_space.sample()
        action_name = action_names[action]
        
        obs, reward, terminated, truncated, info = env.step(action)
        total_reward += reward
        step_count += 1
        
        print(f"  æ­¥éª¤ {step_count}: åŠ¨ä½œ={action_name}, é€Ÿåº¦={env.ego_speed:.2f}, "
              f"è·ç¦»={env.obs_dist:.2f}, å¥–åŠ±={reward:.2f}")
        
        if terminated or truncated:
            print(f"\nâœ… Episodeç»“æŸï¼")
            print(f"   æ€»æ­¥æ•°: {step_count}")
            print(f"   æ€»å¥–åŠ±: {total_reward:.2f}")
            print(f"   ç»ˆæ­¢åŸå› : ", end="")
            if env.obs_dist < 2:
                print("ç¢°æ’")
            elif env.obs_dist > 30:
                print("æˆåŠŸé€šè¿‡")
            else:
                print("å…¶ä»–")
            break
    
    # æ¼”ç¤º5: æ•°æ®ç»Ÿè®¡
    print("\nã€æ¼”ç¤º5ã€‘æ•°æ®ç»Ÿè®¡ - å±•ç¤ºç¯å¢ƒç”Ÿæˆçš„æ•°æ®ç‰¹å¾")
    print("-" * 60)
    
    speeds = []
    distances = []
    rewards = []
    episode_lengths = []
    
    for episode in range(10):
        obs, _ = env.reset()
        speeds.append(env.ego_speed)
        distances.append(env.obs_dist)
        episode_reward = 0
        episode_steps = 0
        
        while episode_steps < 50:
            action = env.action_space.sample()
            obs, reward, terminated, truncated, info = env.step(action)
            episode_reward += reward
            episode_steps += 1
            rewards.append(reward)
            
            if terminated or truncated:
                break
        
        episode_lengths.append(episode_steps)
    
    print(f"åˆå§‹é€Ÿåº¦ç»Ÿè®¡ (10ä¸ªepisode):")
    print(f"  å¹³å‡å€¼: {np.mean(speeds):.2f}")
    print(f"  èŒƒå›´: [{np.min(speeds):.2f}, {np.max(speeds):.2f}]")
    
    print(f"\nåˆå§‹è·ç¦»ç»Ÿè®¡ (10ä¸ªepisode):")
    print(f"  å¹³å‡å€¼: {np.mean(distances):.2f}")
    print(f"  èŒƒå›´: [{np.min(distances):.2f}, {np.max(distances):.2f}]")
    
    print(f"\nå¥–åŠ±ç»Ÿè®¡ (æ‰€æœ‰æ­¥éª¤):")
    print(f"  å¹³å‡å€¼: {np.mean(rewards):.2f}")
    print(f"  æœ€å°å€¼: {np.min(rewards):.2f}")
    print(f"  æœ€å¤§å€¼: {np.max(rewards):.2f}")
    
    print(f"\nEpisodeé•¿åº¦ç»Ÿè®¡:")
    print(f"  å¹³å‡å€¼: {np.mean(episode_lengths):.2f} æ­¥")
    print(f"  èŒƒå›´: [{np.min(episode_lengths)}, {np.max(episode_lengths)}] æ­¥")
    
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ å…³é”®ç‚¹:")
    print("1. æ¯æ¬¡ reset() éƒ½ä¼šç”Ÿæˆæ–°çš„éšæœºåˆå§‹çŠ¶æ€")
    print("2. æ¯æ¬¡ step() éƒ½ä¼šæ ¹æ®åŠ¨ä½œç”Ÿæˆæ–°çš„çŠ¶æ€å’Œå¥–åŠ±")
    print("3. ç¯å¢ƒæœ¬èº«å°±æ˜¯æ•°æ®ç”Ÿæˆå™¨ï¼Œæ— éœ€é¢å¤–çš„è™šæ‹Ÿæ•°æ®")
    print("4. è®­ç»ƒæ—¶ï¼ŒPPOç®—æ³•ä¼šä¸ç¯å¢ƒäº¤äº’ï¼Œè‡ªåŠ¨æ”¶é›†è¿™äº›æ•°æ®")

if __name__ == "__main__":
    demo_environment()

